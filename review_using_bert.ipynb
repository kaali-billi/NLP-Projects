{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"review_using_bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"G_3iKj1GBFY6","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"ae414a4c-5adf-43c8-d6a4-79ab89f6e727"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L-XeILYIBGUW"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkQj_RG5c8KA"},"source":["loading data from the drive \n","file loaded is IMDB Dataset.csv"]},{"cell_type":"code","metadata":{"id":"PxvmtHV3BSYg"},"source":["df = pd.read_csv('/content/drive/My Drive/IMDB Dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zzo_ZY3hBt9G","colab":{"base_uri":"https://localhost:8080/","height":195},"outputId":"152710fe-3385-44cf-c5c4-4c90e73c8355"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"AZ0q-uumCUeT","colab":{"base_uri":"https://localhost:8080/","height":142},"outputId":"4044dcc6-3321-4bf1-bb28-a1ecdc3d37ac"},"source":["!pip install bert-tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qEONx_VnCb-L","colab":{"base_uri":"https://localhost:8080/","height":63},"outputId":"09d32d89-1e5e-4265-bf96-4ed629a3801b"},"source":["from sklearn.model_selection import train_test_split\n","import tensorflow as tf"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8Y9oVghwCoQn"},"source":["import tensorflow_hub as hub\n","import datetime as datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bphiqqc4CxGB","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"028f6260-b50e-42ce-da57-f7b7866950a8"},"source":["import bert\n","from bert import run_classifier\n","from bert import tokenization\n","from bert import optimization"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oEHUJWWMC_f9"},"source":["from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WFD40RXDGGj"},"source":["train = df[:8000]\n","test = df[8000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8pw0F6MDZlE","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f30633e2-87e6-488a-f7ee-3299df0cb3e1"},"source":["train.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['review', 'sentiment'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"qZR1hdTtDelR"},"source":["data = 'review'\n","label = 'sentiment'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nm3zy5w1DoRA","colab":{"base_uri":"https://localhost:8080/","height":228},"outputId":"055b18f0-b740-4d5e-b884-0daee6e16456"},"source":["train[label]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       positive\n","1       positive\n","2       positive\n","3       negative\n","4       positive\n","          ...   \n","2995    positive\n","2996    negative\n","2997    positive\n","2998    negative\n","2999    negative\n","Name: sentiment, Length: 3000, dtype: object"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"TCWUAq9ktpyj","colab":{"base_uri":"https://localhost:8080/","height":228},"outputId":"efd12e10-fd4c-4a1d-8a6c-6ca67c826d15"},"source":["test[label]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3000    negative\n","3001    negative\n","3002    positive\n","3003    negative\n","3004    positive\n","          ...   \n","3995    positive\n","3996    negative\n","3997    negative\n","3998    negative\n","3999    positive\n","Name: sentiment, Length: 1000, dtype: object"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"cZKuCLl0DrK5"},"source":["label_list=['positive','negative']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sumaeESXE7nL"},"source":["# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n","                                                                   text_a = x[data], \n","                                                                   text_b = None, \n","                                                                   label = x[label]), axis = 1)\n","\n","test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[data], \n","                                                                   text_b = None, \n","                                                                   label = x[label]), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1o8Im7ItJkMS","colab":{"base_uri":"https://localhost:8080/","height":142},"outputId":"9f7aabfa-5606-4af5-c981-bc90f592cb15"},"source":["# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oasdAF4gJrW5","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"22ef93ba-3c3a-455b-e787-579dab3deae6"},"source":["len(tokenizer.tokenize(train[data][0]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["415"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"3oo1N2-CKgba"},"source":["Using our tokenizer, we'll call run_classifier.convert_examples_to_features on our InputExamples to convert them into features BERT understands."]},{"cell_type":"code","metadata":{"id":"fLREzADNJ6iS","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"bc7740b5-a5a8-4eee-d9eb-f5f13e5aeedb"},"source":["# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 128\n","# Convert our train and test features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 3000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 3000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] one of the other reviewers has mentioned that after watching just 1 oz episode you ' ll be hooked . they are right , as this is exactly what happened with me . < br / > < br / > the first thing that struck me about oz was its brutality and un ##fl ##in ##ching scenes of violence , which set in right from the word go . trust me , this is not a show for the faint hearted or tim ##id . this show pulls no punches with regards to drugs , sex or violence . its is hardcore , in the classic use of the word . < br / > < br / > it is called oz as that [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] one of the other reviewers has mentioned that after watching just 1 oz episode you ' ll be hooked . they are right , as this is exactly what happened with me . < br / > < br / > the first thing that struck me about oz was its brutality and un ##fl ##in ##ching scenes of violence , which set in right from the word go . trust me , this is not a show for the faint hearted or tim ##id . this show pulls no punches with regards to drugs , sex or violence . its is hardcore , in the classic use of the word . < br / > < br / > it is called oz as that [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2028 1997 1996 2060 15814 2038 3855 2008 2044 3666 2074 1015 11472 2792 2017 1005 2222 2022 13322 1012 2027 2024 2157 1010 2004 2023 2003 3599 2054 3047 2007 2033 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2034 2518 2008 4930 2033 2055 11472 2001 2049 24083 1998 4895 10258 2378 8450 5019 1997 4808 1010 2029 2275 1999 2157 2013 1996 2773 2175 1012 3404 2033 1010 2023 2003 2025 1037 2265 2005 1996 8143 18627 2030 5199 3593 1012 2023 2265 8005 2053 17957 2007 12362 2000 5850 1010 3348 2030 4808 1012 2049 2003 13076 1010 1999 1996 4438 2224 1997 1996 2773 1012 1026 7987 1013 1028 1026 7987 1013 1028 2009 2003 2170 11472 2004 2008 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2028 1997 1996 2060 15814 2038 3855 2008 2044 3666 2074 1015 11472 2792 2017 1005 2222 2022 13322 1012 2027 2024 2157 1010 2004 2023 2003 3599 2054 3047 2007 2033 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 2034 2518 2008 4930 2033 2055 11472 2001 2049 24083 1998 4895 10258 2378 8450 5019 1997 4808 1010 2029 2275 1999 2157 2013 1996 2773 2175 1012 3404 2033 1010 2023 2003 2025 1037 2265 2005 1996 8143 18627 2030 5199 3593 1012 2023 2265 8005 2053 17957 2007 12362 2000 5850 1010 3348 2030 4808 1012 2049 2003 13076 1010 1999 1996 4438 2224 1997 1996 2773 1012 1026 7987 1013 1028 1026 7987 1013 1028 2009 2003 2170 11472 2004 2008 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] a wonderful little production . < br / > < br / > the filming technique is very una ##ss ##uming - very old - time - bbc fashion and gives a comforting , and sometimes discomfort ##ing , sense of realism to the entire piece . < br / > < br / > the actors are extremely well chosen - michael sheen not only \" has got all the polar ##i \" but he has all the voices down pat too ! you can truly see the seam ##less editing guided by the references to williams ' diary entries , not only is it well worth the watching but it is a terrific ##ly written and performed piece . a master ##ful production about [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] a wonderful little production . < br / > < br / > the filming technique is very una ##ss ##uming - very old - time - bbc fashion and gives a comforting , and sometimes discomfort ##ing , sense of realism to the entire piece . < br / > < br / > the actors are extremely well chosen - michael sheen not only \" has got all the polar ##i \" but he has all the voices down pat too ! you can truly see the seam ##less editing guided by the references to williams ' diary entries , not only is it well worth the watching but it is a terrific ##ly written and performed piece . a master ##ful production about [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1037 6919 2210 2537 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 7467 6028 2003 2200 14477 4757 24270 1011 2200 2214 1011 2051 1011 4035 4827 1998 3957 1037 16334 1010 1998 2823 17964 2075 1010 3168 1997 15650 2000 1996 2972 3538 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 5889 2024 5186 2092 4217 1011 2745 20682 2025 2069 1000 2038 2288 2035 1996 11508 2072 1000 2021 2002 2038 2035 1996 5755 2091 6986 2205 999 2017 2064 5621 2156 1996 25180 3238 9260 8546 2011 1996 7604 2000 3766 1005 9708 10445 1010 2025 2069 2003 2009 2092 4276 1996 3666 2021 2009 2003 1037 27547 2135 2517 1998 2864 3538 1012 1037 3040 3993 2537 2055 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1037 6919 2210 2537 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 7467 6028 2003 2200 14477 4757 24270 1011 2200 2214 1011 2051 1011 4035 4827 1998 3957 1037 16334 1010 1998 2823 17964 2075 1010 3168 1997 15650 2000 1996 2972 3538 1012 1026 7987 1013 1028 1026 7987 1013 1028 1996 5889 2024 5186 2092 4217 1011 2745 20682 2025 2069 1000 2038 2288 2035 1996 11508 2072 1000 2021 2002 2038 2035 1996 5755 2091 6986 2205 999 2017 2064 5621 2156 1996 25180 3238 9260 8546 2011 1996 7604 2000 3766 1005 9708 10445 1010 2025 2069 2003 2009 2092 4276 1996 3666 2021 2009 2003 1037 27547 2135 2517 1998 2864 3538 1012 1037 3040 3993 2537 2055 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] i thought this was a wonderful way to spend time on a too hot summer weekend , sitting in the air conditioned theater and watching a light - hearted comedy . the plot is sim ##pl ##istic , but the dialogue is witty and the characters are li ##ka ##ble ( even the well bread suspected serial killer ) . while some may be disappointed when they realize this is not match point 2 : risk addiction , i thought it was proof that woody allen is still fully in control of the style many of us have grown to love . < br / > < br / > this was the most i ' d laughed at one of woody ' s comedies in [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] i thought this was a wonderful way to spend time on a too hot summer weekend , sitting in the air conditioned theater and watching a light - hearted comedy . the plot is sim ##pl ##istic , but the dialogue is witty and the characters are li ##ka ##ble ( even the well bread suspected serial killer ) . while some may be disappointed when they realize this is not match point 2 : risk addiction , i thought it was proof that woody allen is still fully in control of the style many of us have grown to love . < br / > < br / > this was the most i ' d laughed at one of woody ' s comedies in [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1045 2245 2023 2001 1037 6919 2126 2000 5247 2051 2006 1037 2205 2980 2621 5353 1010 3564 1999 1996 2250 22442 4258 1998 3666 1037 2422 1011 18627 4038 1012 1996 5436 2003 21934 24759 6553 1010 2021 1996 7982 2003 25591 1998 1996 3494 2024 5622 2912 3468 1006 2130 1996 2092 7852 6878 7642 6359 1007 1012 2096 2070 2089 2022 9364 2043 2027 5382 2023 2003 2025 2674 2391 1016 1024 3891 13449 1010 1045 2245 2009 2001 6947 2008 13703 5297 2003 2145 3929 1999 2491 1997 1996 2806 2116 1997 2149 2031 4961 2000 2293 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2001 1996 2087 1045 1005 1040 4191 2012 2028 1997 13703 1005 1055 22092 1999 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1045 2245 2023 2001 1037 6919 2126 2000 5247 2051 2006 1037 2205 2980 2621 5353 1010 3564 1999 1996 2250 22442 4258 1998 3666 1037 2422 1011 18627 4038 1012 1996 5436 2003 21934 24759 6553 1010 2021 1996 7982 2003 25591 1998 1996 3494 2024 5622 2912 3468 1006 2130 1996 2092 7852 6878 7642 6359 1007 1012 2096 2070 2089 2022 9364 2043 2027 5382 2023 2003 2025 2674 2391 1016 1024 3891 13449 1010 1045 2245 2009 2001 6947 2008 13703 5297 2003 2145 3929 1999 2491 1997 1996 2806 2116 1997 2149 2031 4961 2000 2293 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2001 1996 2087 1045 1005 1040 4191 2012 2028 1997 13703 1005 1055 22092 1999 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] basically there ' s a family where a little boy ( jake ) thinks there ' s a zombie in his closet & his parents are fighting all the time . < br / > < br / > this movie is slower than a soap opera . . . and suddenly , jake decides to become ram ##bo and kill the zombie . < br / > < br / > ok , first of all when you ' re going to make a film you must decide if its a thriller or a drama ! as a drama the movie is watch ##able . parents are di ##vor ##cing & arguing like in real life . and then we have jake with his closet [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] basically there ' s a family where a little boy ( jake ) thinks there ' s a zombie in his closet & his parents are fighting all the time . < br / > < br / > this movie is slower than a soap opera . . . and suddenly , jake decides to become ram ##bo and kill the zombie . < br / > < br / > ok , first of all when you ' re going to make a film you must decide if its a thriller or a drama ! as a drama the movie is watch ##able . parents are di ##vor ##cing & arguing like in real life . and then we have jake with his closet [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10468 2045 1005 1055 1037 2155 2073 1037 2210 2879 1006 5180 1007 6732 2045 1005 1055 1037 11798 1999 2010 9346 1004 2010 3008 2024 3554 2035 1996 2051 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 3185 2003 12430 2084 1037 7815 3850 1012 1012 1012 1998 3402 1010 5180 7288 2000 2468 8223 5092 1998 3102 1996 11798 1012 1026 7987 1013 1028 1026 7987 1013 1028 7929 1010 2034 1997 2035 2043 2017 1005 2128 2183 2000 2191 1037 2143 2017 2442 5630 2065 2049 1037 10874 2030 1037 3689 999 2004 1037 3689 1996 3185 2003 3422 3085 1012 3008 2024 4487 14550 6129 1004 9177 2066 1999 2613 2166 1012 1998 2059 2057 2031 5180 2007 2010 9346 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10468 2045 1005 1055 1037 2155 2073 1037 2210 2879 1006 5180 1007 6732 2045 1005 1055 1037 11798 1999 2010 9346 1004 2010 3008 2024 3554 2035 1996 2051 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 3185 2003 12430 2084 1037 7815 3850 1012 1012 1012 1998 3402 1010 5180 7288 2000 2468 8223 5092 1998 3102 1996 11798 1012 1026 7987 1013 1028 1026 7987 1013 1028 7929 1010 2034 1997 2035 2043 2017 1005 2128 2183 2000 2191 1037 2143 2017 2442 5630 2065 2049 1037 10874 2030 1037 3689 999 2004 1037 3689 1996 3185 2003 3422 3085 1012 3008 2024 4487 14550 6129 1004 9177 2066 1999 2613 2166 1012 1998 2059 2057 2031 5180 2007 2010 9346 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] pet ##ter matt ##ei ' s \" love in the time of money \" is a visually stunning film to watch . mr . matt ##ei offers us a vivid portrait about human relations . this is a movie that seems to be telling us what money , power and success do to people in the different situations we encounter . < br / > < br / > this being a variation on the arthur sc ##hn ##itz ##ler ' s play about the same theme , the director transfers the action to the present time new york where all these different characters meet and connect . each one is connected in one way , or another to the next person , but no one [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] pet ##ter matt ##ei ' s \" love in the time of money \" is a visually stunning film to watch . mr . matt ##ei offers us a vivid portrait about human relations . this is a movie that seems to be telling us what money , power and success do to people in the different situations we encounter . < br / > < br / > this being a variation on the arthur sc ##hn ##itz ##ler ' s play about the same theme , the director transfers the action to the present time new york where all these different characters meet and connect . each one is connected in one way , or another to the next person , but no one [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 9004 3334 4717 7416 1005 1055 1000 2293 1999 1996 2051 1997 2769 1000 2003 1037 17453 14726 2143 2000 3422 1012 2720 1012 4717 7416 4107 2149 1037 14954 6533 2055 2529 4262 1012 2023 2003 1037 3185 2008 3849 2000 2022 4129 2149 2054 2769 1010 2373 1998 3112 2079 2000 2111 1999 1996 2367 8146 2057 8087 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2108 1037 8386 2006 1996 4300 8040 7295 8838 3917 1005 1055 2377 2055 1996 2168 4323 1010 1996 2472 15210 1996 2895 2000 1996 2556 2051 2047 2259 2073 2035 2122 2367 3494 3113 1998 7532 1012 2169 2028 2003 4198 1999 2028 2126 1010 2030 2178 2000 1996 2279 2711 1010 2021 2053 2028 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 9004 3334 4717 7416 1005 1055 1000 2293 1999 1996 2051 1997 2769 1000 2003 1037 17453 14726 2143 2000 3422 1012 2720 1012 4717 7416 4107 2149 1037 14954 6533 2055 2529 4262 1012 2023 2003 1037 3185 2008 3849 2000 2022 4129 2149 2054 2769 1010 2373 1998 3112 2079 2000 2111 1999 1996 2367 8146 2057 8087 1012 1026 7987 1013 1028 1026 7987 1013 1028 2023 2108 1037 8386 2006 1996 4300 8040 7295 8838 3917 1005 1055 2377 2055 1996 2168 4323 1010 1996 2472 15210 1996 2895 2000 1996 2556 2051 2047 2259 2073 2035 2122 2367 3494 3113 1998 7532 1012 2169 2028 2003 4198 1999 2028 2126 1010 2030 2178 2000 1996 2279 2711 1010 2021 2053 2028 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1000\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] i bought a set of 4 dvds for 10 bucks at my local sun ##co ##ast , which contained this movie and three other trash ##y horror flick ##s ( including its sequel \" witchcraft xi \" ) . so basically i paid the rock bottom price of $ 2 . 50 for this movie , if you do the math . i can ' t exactly say i was ripped off . i have a thing for trash ##y horror movies , but this is the kind of trash that gives trash a bad name . the budget couldn ' t be over $ 1 , 000 ( though it appears as if they spent a total of $ 1 . 50 ) . i [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] i bought a set of 4 dvds for 10 bucks at my local sun ##co ##ast , which contained this movie and three other trash ##y horror flick ##s ( including its sequel \" witchcraft xi \" ) . so basically i paid the rock bottom price of $ 2 . 50 for this movie , if you do the math . i can ' t exactly say i was ripped off . i have a thing for trash ##y horror movies , but this is the kind of trash that gives trash a bad name . the budget couldn ' t be over $ 1 , 000 ( though it appears as if they spent a total of $ 1 . 50 ) . i [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1045 4149 1037 2275 1997 1018 22477 2005 2184 14189 2012 2026 2334 3103 3597 14083 1010 2029 4838 2023 3185 1998 2093 2060 11669 2100 5469 17312 2015 1006 2164 2049 8297 1000 21599 8418 1000 1007 1012 2061 10468 1045 3825 1996 2600 3953 3976 1997 1002 1016 1012 2753 2005 2023 3185 1010 2065 2017 2079 1996 8785 1012 1045 2064 1005 1056 3599 2360 1045 2001 9157 2125 1012 1045 2031 1037 2518 2005 11669 2100 5469 5691 1010 2021 2023 2003 1996 2785 1997 11669 2008 3957 11669 1037 2919 2171 1012 1996 5166 2481 1005 1056 2022 2058 1002 1015 1010 2199 1006 2295 2009 3544 2004 2065 2027 2985 1037 2561 1997 1002 1015 1012 2753 1007 1012 1045 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1045 4149 1037 2275 1997 1018 22477 2005 2184 14189 2012 2026 2334 3103 3597 14083 1010 2029 4838 2023 3185 1998 2093 2060 11669 2100 5469 17312 2015 1006 2164 2049 8297 1000 21599 8418 1000 1007 1012 2061 10468 1045 3825 1996 2600 3953 3976 1997 1002 1016 1012 2753 2005 2023 3185 1010 2065 2017 2079 1996 8785 1012 1045 2064 1005 1056 3599 2360 1045 2001 9157 2125 1012 1045 2031 1037 2518 2005 11669 2100 5469 5691 1010 2021 2023 2003 1996 2785 1997 11669 2008 3957 11669 1037 2919 2171 1012 1996 5166 2481 1005 1056 2022 2058 1002 1015 1010 2199 1006 2295 2009 3544 2004 2065 2027 2985 1037 2561 1997 1002 1015 1012 2753 1007 1012 1045 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] i am still trying to figure out what the target of this movie was : 1 ) whether to show how stupid , di ##sor ##gan ##ized , un ##pro ##fe ##ssion ##al and arrogant the police is ( i surely could add various adjective ##s here , but i think my point on this is clear ) . 2 ) whether to show how a twisted - minded crook that does not know what he wants from himself can create chaos . 3 ) whether to show if a persistent detective will solve a case just by asking the criminal the same stupid question over and over again till the criminal answers ? 4 ) or was it just to show that any 90 minutes [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] i am still trying to figure out what the target of this movie was : 1 ) whether to show how stupid , di ##sor ##gan ##ized , un ##pro ##fe ##ssion ##al and arrogant the police is ( i surely could add various adjective ##s here , but i think my point on this is clear ) . 2 ) whether to show how a twisted - minded crook that does not know what he wants from himself can create chaos . 3 ) whether to show if a persistent detective will solve a case just by asking the criminal the same stupid question over and over again till the criminal answers ? 4 ) or was it just to show that any 90 minutes [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1045 2572 2145 2667 2000 3275 2041 2054 1996 4539 1997 2023 3185 2001 1024 1015 1007 3251 2000 2265 2129 5236 1010 4487 21748 5289 3550 1010 4895 21572 7959 28231 2389 1998 15818 1996 2610 2003 1006 1045 7543 2071 5587 2536 24931 2015 2182 1010 2021 1045 2228 2026 2391 2006 2023 2003 3154 1007 1012 1016 1007 3251 2000 2265 2129 1037 6389 1011 13128 19302 2008 2515 2025 2113 2054 2002 4122 2013 2370 2064 3443 8488 1012 1017 1007 3251 2000 2265 2065 1037 14516 6317 2097 9611 1037 2553 2074 2011 4851 1996 4735 1996 2168 5236 3160 2058 1998 2058 2153 6229 1996 4735 6998 1029 1018 1007 2030 2001 2009 2074 2000 2265 2008 2151 3938 2781 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1045 2572 2145 2667 2000 3275 2041 2054 1996 4539 1997 2023 3185 2001 1024 1015 1007 3251 2000 2265 2129 5236 1010 4487 21748 5289 3550 1010 4895 21572 7959 28231 2389 1998 15818 1996 2610 2003 1006 1045 7543 2071 5587 2536 24931 2015 2182 1010 2021 1045 2228 2026 2391 2006 2023 2003 3154 1007 1012 1016 1007 3251 2000 2265 2129 1037 6389 1011 13128 19302 2008 2515 2025 2113 2054 2002 4122 2013 2370 2064 3443 8488 1012 1017 1007 3251 2000 2265 2065 1037 14516 6317 2097 9611 1037 2553 2074 2011 4851 1996 4735 1996 2168 5236 3160 2058 1998 2058 2153 6229 1996 4735 6998 1029 1018 1007 2030 2001 2009 2074 2000 2265 2008 2151 3938 2781 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] for those not in the know , the as ##ter ##ix books are a hugely successful series of comic books about a village of indo ##mit ##able gaul ##s who resist caesar ' s invasion thanks to a magic potion that render ##s them in ##vu ##ln ##era ##ble super ##men . there have been several animated features ( only one of them , the twelve tasks of as ##ter ##ix really capturing the wit and spirit of the books despite being an original screen story ) before a perfectly cast christian cl ##avi ##er and gerard de ##par ##die ##u took the lead roles in two live action adaptations that proved colossal ##ly successful throughout europe but made no impression whatsoever in the english - [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] for those not in the know , the as ##ter ##ix books are a hugely successful series of comic books about a village of indo ##mit ##able gaul ##s who resist caesar ' s invasion thanks to a magic potion that render ##s them in ##vu ##ln ##era ##ble super ##men . there have been several animated features ( only one of them , the twelve tasks of as ##ter ##ix really capturing the wit and spirit of the books despite being an original screen story ) before a perfectly cast christian cl ##avi ##er and gerard de ##par ##die ##u took the lead roles in two live action adaptations that proved colossal ##ly successful throughout europe but made no impression whatsoever in the english - [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2005 2216 2025 1999 1996 2113 1010 1996 2004 3334 7646 2808 2024 1037 27564 3144 2186 1997 5021 2808 2055 1037 2352 1997 11424 22930 3085 26522 2015 2040 9507 11604 1005 1055 5274 4283 2000 1037 3894 26722 2008 17552 2015 2068 1999 19722 19666 6906 3468 3565 3549 1012 2045 2031 2042 2195 6579 2838 1006 2069 2028 1997 2068 1010 1996 4376 8518 1997 2004 3334 7646 2428 11847 1996 15966 1998 4382 1997 1996 2808 2750 2108 2019 2434 3898 2466 1007 2077 1037 6669 3459 3017 18856 18891 2121 1998 11063 2139 19362 10265 2226 2165 1996 2599 4395 1999 2048 2444 2895 17241 2008 4928 29523 2135 3144 2802 2885 2021 2081 2053 8605 18971 1999 1996 2394 1011 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2005 2216 2025 1999 1996 2113 1010 1996 2004 3334 7646 2808 2024 1037 27564 3144 2186 1997 5021 2808 2055 1037 2352 1997 11424 22930 3085 26522 2015 2040 9507 11604 1005 1055 5274 4283 2000 1037 3894 26722 2008 17552 2015 2068 1999 19722 19666 6906 3468 3565 3549 1012 2045 2031 2042 2195 6579 2838 1006 2069 2028 1997 2068 1010 1996 4376 8518 1997 2004 3334 7646 2428 11847 1996 15966 1998 4382 1997 1996 2808 2750 2108 2019 2434 3898 2466 1007 2077 1037 6669 3459 3017 18856 18891 2121 1998 11063 2139 19362 10265 2226 2165 1996 2599 4395 1999 2048 2444 2895 17241 2008 4928 29523 2135 3144 2802 2885 2021 2081 2053 8605 18971 1999 1996 2394 1011 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] what ' s this ? a canadian produced zombie flick that i have never heard of before . a mort ##icia ##n works on the body of a recently deceased young man . this allows for an extended flashback that show how the guy got there . basically , he and friends went to a cemetery on friday the 13th and raised the dead thanks to his silly chanting . cut back to the mor ##gue where our dead body comes back to life and kills the mort ##icia ##n and owner ( who gets his eyes popped out ) . the final w ##tf ? shot has the funeral home owner in a straight jacket and screaming , \" i ' m not crazy ! [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] what ' s this ? a canadian produced zombie flick that i have never heard of before . a mort ##icia ##n works on the body of a recently deceased young man . this allows for an extended flashback that show how the guy got there . basically , he and friends went to a cemetery on friday the 13th and raised the dead thanks to his silly chanting . cut back to the mor ##gue where our dead body comes back to life and kills the mort ##icia ##n and owner ( who gets his eyes popped out ) . the final w ##tf ? shot has the funeral home owner in a straight jacket and screaming , \" i ' m not crazy ! [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2054 1005 1055 2023 1029 1037 3010 2550 11798 17312 2008 1045 2031 2196 2657 1997 2077 1012 1037 22294 24108 2078 2573 2006 1996 2303 1997 1037 3728 10181 2402 2158 1012 2023 4473 2005 2019 3668 21907 2008 2265 2129 1996 3124 2288 2045 1012 10468 1010 2002 1998 2814 2253 2000 1037 4528 2006 5958 1996 6122 1998 2992 1996 2757 4283 2000 2010 10021 22417 1012 3013 2067 2000 1996 22822 9077 2073 2256 2757 2303 3310 2067 2000 2166 1998 8563 1996 22294 24108 2078 1998 3954 1006 2040 4152 2010 2159 10538 2041 1007 1012 1996 2345 1059 24475 1029 2915 2038 1996 6715 2188 3954 1999 1037 3442 6598 1998 7491 1010 1000 1045 1005 1049 2025 4689 999 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2054 1005 1055 2023 1029 1037 3010 2550 11798 17312 2008 1045 2031 2196 2657 1997 2077 1012 1037 22294 24108 2078 2573 2006 1996 2303 1997 1037 3728 10181 2402 2158 1012 2023 4473 2005 2019 3668 21907 2008 2265 2129 1996 3124 2288 2045 1012 10468 1010 2002 1998 2814 2253 2000 1037 4528 2006 5958 1996 6122 1998 2992 1996 2757 4283 2000 2010 10021 22417 1012 3013 2067 2000 1996 22822 9077 2073 2256 2757 2303 3310 2067 2000 2166 1998 8563 1996 22294 24108 2078 1998 3954 1006 2040 4152 2010 2159 10538 2041 1007 1012 1996 2345 1059 24475 1029 2915 2038 1996 6715 2188 3954 1999 1037 3442 6598 1998 7491 1010 1000 1045 1005 1049 2025 4689 999 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: negative (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the full title of this film is ' may you be in heaven a half hour before the devil knows you ' re dead ' , a re ##word ##ing of the old irish toast ' may you have food and rai ##ment , a soft pillow for your head ; may you be 40 years in heaven , before the devil knows you ' re dead . ' first time screenwriter kelly masters ##on ( with some modifications by director sidney lu ##met ) has con ##co ##cted a mel ##od ##rama that explores just how fragmented a family can become when external forces drive the members to un ##thi ##nka ##ble extremes . in this film the viewer is allowed to witness the gradual [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] the full title of this film is ' may you be in heaven a half hour before the devil knows you ' re dead ' , a re ##word ##ing of the old irish toast ' may you have food and rai ##ment , a soft pillow for your head ; may you be 40 years in heaven , before the devil knows you ' re dead . ' first time screenwriter kelly masters ##on ( with some modifications by director sidney lu ##met ) has con ##co ##cted a mel ##od ##rama that explores just how fragmented a family can become when external forces drive the members to un ##thi ##nka ##ble extremes . in this film the viewer is allowed to witness the gradual [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 2440 2516 1997 2023 2143 2003 1005 2089 2017 2022 1999 6014 1037 2431 3178 2077 1996 6548 4282 2017 1005 2128 2757 1005 1010 1037 2128 18351 2075 1997 1996 2214 3493 15174 1005 2089 2017 2031 2833 1998 15547 3672 1010 1037 3730 10005 2005 2115 2132 1025 2089 2017 2022 2871 2086 1999 6014 1010 2077 1996 6548 4282 2017 1005 2128 2757 1012 1005 2034 2051 11167 5163 5972 2239 1006 2007 2070 12719 2011 2472 11430 11320 11368 1007 2038 9530 3597 10985 1037 11463 7716 14672 2008 15102 2074 2129 26872 1037 2155 2064 2468 2043 6327 2749 3298 1996 2372 2000 4895 15222 25804 3468 28800 1012 1999 2023 2143 1996 13972 2003 3039 2000 7409 1996 16612 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1996 2440 2516 1997 2023 2143 2003 1005 2089 2017 2022 1999 6014 1037 2431 3178 2077 1996 6548 4282 2017 1005 2128 2757 1005 1010 1037 2128 18351 2075 1997 1996 2214 3493 15174 1005 2089 2017 2031 2833 1998 15547 3672 1010 1037 3730 10005 2005 2115 2132 1025 2089 2017 2022 2871 2086 1999 6014 1010 2077 1996 6548 4282 2017 1005 2128 2757 1012 1005 2034 2051 11167 5163 5972 2239 1006 2007 2070 12719 2011 2472 11430 11320 11368 1007 2038 9530 3597 10985 1037 11463 7716 14672 2008 15102 2074 2129 26872 1037 2155 2064 2468 2043 6327 2749 3298 1996 2372 2000 4895 15222 25804 3468 28800 1012 1999 2023 2143 1996 13972 2003 3039 2000 7409 1996 16612 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: positive (id = 0)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bp0HBUKXKXMS"},"source":["def create_model(is_predicting,input_ids,segment_ids,input_mask,labels,num_labels):\n","  bert_module = hub.Module(BERT_MODEL_HUB,\n","                          trainable = True)\n","  bert_inputs=dict(input_ids=input_ids,\n","                   input_mask=input_mask,\n","                   segment_ids=segment_ids)\n","  bert_outputs = bert_module(inputs=bert_inputs,\n","                             signature=\"tokens\",\n","                             as_dict=True)\n","  \n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","    # Create our own layer to tune for our data\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","# calculating output logs by matrix multiplication\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    #adding biases\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    #returning probabilites using softmax\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NImG2ibQNi1v"},"source":["# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        f1_score = tf.contrib.metrics.f1_score(\n","            label_ids,\n","            predicted_labels)\n","        auc = tf.metrics.auc(\n","            label_ids,\n","            predicted_labels)\n","        recall = tf.metrics.recall(\n","            label_ids,\n","            predicted_labels)\n","        precision = tf.metrics.precision(\n","            label_ids,\n","            predicted_labels) \n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        return {\n","            \"eval_accuracy\": accuracy,\n","            #\"f1_score\": f1_score,\n","            #\"auc\": auc,\n","            \"precision\": precision,\n","            #\"recall\": recall,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","        }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaV9r_FQOE7y"},"source":["# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 1.0\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xIvw-7uZuDSQ","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"27e48783-11a8-4ad6-b63f-05973c84c525"},"source":["len(train_features)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3000"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"ZfUsxX8xPBbz"},"source":["# Compute # train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yO2rrgiiPy98"},"source":["# Specify outpit directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mge_RSp0PEnj","colab":{"base_uri":"https://localhost:8080/","height":318},"outputId":"536e9e9a-ff99-4a9f-f8bc-bbf454db0efe"},"source":["model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwqjowj83\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwqjowj83\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwqjowj83', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6f06eded30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwqjowj83', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6f06eded30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WBzVpzw9PHIW"},"source":["# Create an input function for training.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-S9kj0MQKav","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"24b62e11-aee8-46db-93dd-ec6af24af73e"},"source":["print(f'Beginning Training!')\n","#current_time = datetime.\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","#print(\"Training took time \", datetime.now() - current_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-19-18ce27ecc0e3>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-19-18ce27ecc0e3>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpwqjowj83/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpwqjowj83/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.6755309, step = 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.6755309, step = 1\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Qsx15AzmQQM1"},"source":["test_input_fn = run_classifier.input_fn_builder(\n","    features=test_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTm44nl3cI05","colab":{"base_uri":"https://localhost:8080/","height":600},"outputId":"88743ea9-250a-4741-d048-5949bbe24e3e"},"source":["estimator.evaluate(input_fn=test_input_fn, steps=None)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-02-09T17:56:27Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-02-09T17:56:27Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /tmp/tmp7r59ygp5/model.ckpt-250\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /tmp/tmp7r59ygp5/model.ckpt-250\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-02-09-23:26:10\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-02-09-23:26:10\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 250: eval_accuracy = 0.8733478, false_negatives = 3062.0, false_positives = 2764.0, global_step = 250, loss = 0.29662132, precision = 0.8781036, true_negatives = 20263.0, true_positives = 19911.0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 250: eval_accuracy = 0.8733478, false_negatives = 3062.0, false_positives = 2764.0, global_step = 250, loss = 0.29662132, precision = 0.8781036, true_negatives = 20263.0, true_positives = 19911.0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: /tmp/tmp7r59ygp5/model.ckpt-250\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: /tmp/tmp7r59ygp5/model.ckpt-250\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'eval_accuracy': 0.8733478,\n"," 'false_negatives': 3062.0,\n"," 'false_positives': 2764.0,\n"," 'global_step': 250,\n"," 'loss': 0.29662132,\n"," 'precision': 0.8781036,\n"," 'true_negatives': 20263.0,\n"," 'true_positives': 19911.0}"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"bZz88X_nGAJU"},"source":[""],"execution_count":null,"outputs":[]}]}